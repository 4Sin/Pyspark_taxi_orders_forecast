{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aed52d2-cdda-4261-b1f2-1a7392c8de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prophet in /opt/conda/lib/python3.11/site-packages (1.1.4)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /opt/conda/lib/python3.11/site-packages (from prophet) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.11/site-packages (from prophet) (1.24.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from prophet) (3.7.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/conda/lib/python3.11/site-packages (from prophet) (1.5.3)\n",
      "Requirement already satisfied: LunarCalendar>=0.0.9 in /opt/conda/lib/python3.11/site-packages (from prophet) (0.0.9)\n",
      "Requirement already satisfied: convertdate>=2.1.2 in /opt/conda/lib/python3.11/site-packages (from prophet) (2.4.0)\n",
      "Requirement already satisfied: holidays>=0.25 in /opt/conda/lib/python3.11/site-packages (from prophet) (0.32)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.11/site-packages (from prophet) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/conda/lib/python3.11/site-packages (from prophet) (4.66.1)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.11/site-packages (from prophet) (6.0.1)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /opt/conda/lib/python3.11/site-packages (from convertdate>=2.1.2->prophet) (0.5.12)\n",
      "Requirement already satisfied: ephem>=3.7.5.3 in /opt/conda/lib/python3.11/site-packages (from LunarCalendar>=0.0.9->prophet) (4.1.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from LunarCalendar>=0.0.9->prophet) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.0->prophet) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e55604-8ceb-4e4d-bbce-040128d8890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from prophet import Prophet\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc28b15b-9881-49bd-aa24-4b81886148ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SPARK_MASTER_IP = '172.18.0.2' \n",
    "spark = SparkSession.builder.appName(\"pyspark-taxi-forecasting\") \\\n",
    "    .master(f\"spark://{SPARK_MASTER_IP}:7077\") \\\n",
    "    .config(\"spark.executor.cores\", 2) \\\n",
    "    .config('spark.local.dir', 'spark_tmp/') \\\n",
    "    .config(\"spark.task.cpus\", 2) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4371b-f112-4eda-b558-3932de95d341",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder.appName(\"Introduction to Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef0d79f-5126-483d-8f9a-14962bc2f332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1727e03cafad:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://172.18.0.2:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-taxi-forecasting</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f323be76990>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0c5b9f-85c9-4308-817e-e7ca9198592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsp22 = spark.read.csv(\"Taxi_Trips_-_2022.csv\", header = True, inferSchema = True)\n",
    "dfsp23 = spark.read.csv(\"Taxi_Trips_-_2023.csv\", header = True, inferSchema = True)\n",
    "lim23 = '2023-07-31 23:00'\n",
    "dfsp23 = dfsp23.filter(F.to_timestamp(F.col('Trip Start Timestamp'), 'MM/dd/yyyy hh:mm:ss a')<lim23)\n",
    "dfsp = dfsp22.union(dfsp23) \\\n",
    "    .filter(F.to_timestamp(F.col('Trip Start Timestamp'), 'MM/dd/yyyy hh:mm:ss a')<'2023-07-31 23:00') \n",
    "#переименуем колонки в df\n",
    "for col in dfsp.columns:\n",
    "    dfsp = dfsp.withColumnRenamed(col, col.lower().replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b06581c-06f3-45da-b936-5d28e2a6f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv(\"y_true_2023-07-31_23-00_UTC0.csv\", header = True, inferSchema = True)\n",
    "\n",
    "test = test.withColumn('ds', test['hours']) \\\n",
    "    .withColumn('pickup_community_area', test['Pickup Community Area']) \\\n",
    "    .withColumn('y', test['trips_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539a9acc-1e10-499c-8eb3-12cc09c00e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обработка данных\n",
    "dfsp = dfsp.fillna(0, subset=['pickup_community_area']) \\\n",
    "    .drop('pickup_census_tract', 'pickup_centroid_location', \n",
    "                 'tips', 'tolls', 'extras', \n",
    "                 \"fare\", 'company', 'payment_type', \n",
    "                 'dropoff_census_tract', 'dropoff_centroid_latitude', 'dropoff_centroid_longitude', 'dropoff_centroid__location' ) \\\n",
    "    .withColumn(\"trip_end_timestamp\", F.date_trunc(\"hour\", to_timestamp(\"trip_end_timestamp\", \"MM/dd/yyyy hh:mm:ss a\"))) \\\n",
    "    .withColumn(\"trip_start_timestamp\", F.date_trunc(\"hour\", to_timestamp(\"trip_start_timestamp\", \"MM/dd/yyyy hh:mm:ss a\"))) \\\n",
    "    .filter((dfsp.trip_seconds <= dfsp.approxQuantile(\"trip_seconds\", [0.025, 0.99], 0.005)[1]) \\\n",
    "                    |(dfsp.trip_miles <= dfsp.approxQuantile(\"trip_miles\", [0.025, 0.99], 0.005)[1]) \\\n",
    "                     |(dfsp.trip_total <= dfsp.approxQuantile(\"trip_total\", [0.025, 0.99], 0.005)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27162a4-1d9d-4e74-9bc7-63636e1ca1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группировка\n",
    "dfsp_grouped = dfsp \\\n",
    "    .groupby('pickup_community_area', \"trip_start_timestamp\").agg(\n",
    "    count('trip_id').alias('trips_count'), \n",
    "    median(\"trip_total\").alias('cost_median'), \n",
    "    median('trip_miles').alias('miles_median'),\n",
    "    median(\"trip_seconds\").alias('seconds_median'),\n",
    "    median(\"pickup_centroid_latitude\").alias('centroid_lat_median'),\n",
    "    median(\"pickup_centroid_longitude\").alias('centroid_long_median'),\n",
    "    countDistinct('taxi_id').alias('taxi_countdist')\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74f7a35c-7166-46de-ad2b-cc362a850b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание полной временной шкалы и включение туда данных\n",
    "max_hour = '2023-07-31 23:00:00'#max(dfsp_timed.trip_start_timestamp) \n",
    "min_hour = '2022-01-01 00:00:00' #min(dfsp_timed.trip_start_timestamp)# \n",
    "hours = spark.createDataFrame([(min_hour, max_hour)], [\"min_hour\", \"max_hour\"]) \\\n",
    "    .selectExpr(\"explode(sequence(to_timestamp(min_hour), to_timestamp(max_hour), interval 1 hour)) as time\") \n",
    "hours = hours.select(F.date_trunc('hour', hours.time).alias(\"hour_cons\")) \n",
    "\n",
    "allhours_schema = StructType([ \\\n",
    "                                StructField(\"hour_cons\",TimestampType(),True), \\\n",
    "                                StructField(\"pickup_community_area\",IntegerType (),True) \\\n",
    "                              ])\n",
    "all_hours = spark.createDataFrame([], allhours_schema)\n",
    "for i in range(78):\n",
    "    temp = hours.withColumn('pickup_community_area', lit(i))\n",
    "    all_hours = all_hours.union(temp)\n",
    "\n",
    "all_hours = all_hours \\\n",
    "    .join(dfsp_grouped, (all_hours.hour_cons == dfsp_grouped.trip_start_timestamp) &\n",
    "                (all_hours.pickup_community_area == dfsp_grouped.pickup_community_area), 'left_outer') \\\n",
    "                .select(\n",
    "                all_hours.pickup_community_area,\n",
    "                all_hours.hour_cons,\n",
    "                dfsp_grouped.taxi_countdist,\n",
    "                dfsp_grouped.trips_count,\n",
    "                dfsp_grouped.cost_median,\n",
    "                dfsp_grouped.miles_median,\n",
    "                dfsp_grouped.seconds_median\n",
    "                ) \\\n",
    "    .na.fill(value=0).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234110a5-811a-49fd-9ef9-4d8d05968db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hours.toPandas().to_csv('all_hours_short_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806726b-821f-415a-94fa-24ee37abacc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
